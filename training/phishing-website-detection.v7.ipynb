{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"","version":""},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12693261,"sourceType":"datasetVersion","datasetId":8021783},{"sourceId":12742804,"sourceType":"datasetVersion","datasetId":8055177},{"sourceId":12751295,"sourceType":"datasetVersion","datasetId":8060741}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predict from web_code","metadata":{"id":"fd515a00"}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\nfrom sklearn.pipeline import Pipeline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.preprocessing import StandardScaler\nimport joblib\nfrom scipy.sparse import save_npz, load_npz, vstack","metadata":{"executionInfo":{"elapsed":8513,"status":"ok","timestamp":1754287609770,"user":{"displayName":"Iqbal Hossain Emon","userId":"10223218326935169959"},"user_tz":-360},"id":"8d7021e6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dataset = pd.read_csv(\n#     \"/content/drive/MyDrive/Colab/phishing/phishing_complete_dataset.csv\",\n#     sep=\",\",\n#     quotechar='\"',\n#     nrows=10000\n# )\n\n# dataset.head()","metadata":{"executionInfo":{"elapsed":40511,"status":"ok","timestamp":1754287650279,"user":{"displayName":"Iqbal Hossain Emon","userId":"10223218326935169959"},"user_tz":-360},"id":"0a4c5149","outputId":"cedd98f3-4469-45ed-aeaf-4250beb87b17"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Check dataset shape and class distribution\n# print(f\"Dataset shape: {dataset.shape}\")\n# print(f\"\\nClass distribution:\")\n# print(dataset['result'].value_counts())\n# print(f\"\\nClass distribution (percentages):\")\n# print(dataset['result'].value_counts(normalize=True) * 100)\n\n# # Check for missing values\n# print(f\"\\nMissing values:\")\n# print(dataset.isnull().sum())\n\n# # Check length of webpage_code\n# dataset['code_length'] = dataset['webpage_code'].str.len()\n# print(f\"\\nWebpage code length statistics:\")\n# print(dataset['code_length'].describe())","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1754287650295,"user":{"displayName":"Iqbal Hossain Emon","userId":"10223218326935169959"},"user_tz":-360},"id":"05f2f792","outputId":"0ac0f5c0-cd0a-4d89-c4e0-9689ab748ac6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Prepare the data\n# # Features (X) = webpage_code, Target (y) = result\n# X = dataset['webpage_code']\n# y = dataset['result']\n\n# print(f\"Features shape: {X.shape}\")\n# print(f\"Target shape: {y.shape}\")\n# print(f\"Target distribution:\\n{y.value_counts()}\")\n\n# # Split the data into training and testing sets\n# X_train, X_test, y_train, y_test = train_test_split(\n#     X, y, test_size=0.2, random_state=42, stratify=y\n# )\n\n# del X\n# del y\n# del dataset\n\n# print(f\"\\nTraining set size: {len(X_train)}\")\n# print(f\"Test set size: {len(X_test)}\")\n# print(f\"Training target distribution:\\n{y_train.value_counts()}\")\n# print(f\"Test target distribution:\\n{y_test.value_counts()}\")","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1754287650301,"user":{"displayName":"Iqbal Hossain Emon","userId":"10223218326935169959"},"user_tz":-360},"id":"84e5f8d5","outputId":"a62f46c4-45bb-4fea-a78d-27e750fe0e4c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Vectorize once for both TF-IDF and CountVectorizer, then release raw data\n# tfidf_vectorizer = TfidfVectorizer(\n#     max_features=5000, stop_words='english', ngram_range=(1, 2))\n# count_vectorizer = CountVectorizer(\n#     max_features=5000, stop_words='english', ngram_range=(1, 2))\n\n# # Fit and transform training data\n# X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n# X_test_tfidf = tfidf_vectorizer.transform(X_test)\n# X_train_count = count_vectorizer.fit_transform(X_train)\n# X_test_count = count_vectorizer.transform(X_test)\n\n# # Release raw text data from memory\n# del X_train\n# del X_test","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntfidf_vectorizer = joblib.load(\"/kaggle/input/tf-idf-dataset/tfidf_vectorizer.joblib\")\ncount_vectorizer = joblib.load(\"/kaggle/input/count-dataset/count_vectorizer.joblib\")\n\n\nX_train_tfidf = load_npz(\"/kaggle/input/tf-idf-dataset/X_train_tfidf.npz\")\nX_test_tfidf = load_npz(\"/kaggle/input/tf-idf-dataset/X_test_tfidf.npz\")\n\nX_train_count = load_npz(\"/kaggle/input/count-dataset/X_train_count.npz\")\nX_test_count = load_npz(\"/kaggle/input/count-dataset/X_test_count.npz\")\n\n# tf-idf\ny_train = np.load(\"/kaggle/input/tf-idf-dataset/y_train_tfidf.npy\")\ny_test = np.load(\"/kaggle/input/tf-idf-dataset/y_test_tfidf.npy\")\n# count\ny_train = np.load(\"/kaggle/input/count-dataset/y_train_count.npy\")\ny_test = np.load(\"/kaggle/input/count-dataset/y_test_count.npy\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = {}\n\nclassifiers_tfidf = {\n    'Gradient Boosting (TF-IDF)': GradientBoostingClassifier(random_state=42),\n    'XGBoost (TF-IDF)': xgb.XGBClassifier(random_state=42, verbosity=0),\n    'LightGBM (TF-IDF)': lgb.LGBMClassifier(random_state=42, verbose=-1),\n    'Extra Trees (TF-IDF)': ExtraTreesClassifier(n_estimators=100, random_state=42)\n}\n\nclassifiers_count = {\n    'Gradient Boosting (Count)': GradientBoostingClassifier(random_state=42),\n    'XGBoost (Count)': xgb.XGBClassifier(random_state=42, verbosity=0),\n    'Extra Trees (Count)': ExtraTreesClassifier(n_estimators=100, random_state=42)\n}\n\nprint(\"Training and evaluating models...\")\nprint(\"=\" * 50)\n\n# Train TF-IDF models\nfor name, clf in classifiers_tfidf.items():\n    print(f\"\\nTraining {name}...\")\n    try:\n        clf.fit(X_train_tfidf, y_train)\n        y_pred = clf.predict(X_test_tfidf)\n        accuracy = accuracy_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n        results[name] = {\n            'accuracy': accuracy,\n            'f1_score': f1,\n            'predictions': y_pred,\n            'model': clf\n        }\n    except Exception as e:\n        print(f\"Error training {name}: {e}\")\n\n# Train CountVectorizer models\nfor name, clf in classifiers_count.items():\n    print(f\"\\nTraining {name}...\")\n    try:\n        clf.fit(X_train_count, y_train)\n        y_pred = clf.predict(X_test_count)\n        accuracy = accuracy_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n        results[name] = {\n            'accuracy': accuracy,\n            'f1_score': f1,\n            'predictions': y_pred,\n            'model': clf\n        }\n    except Exception as e:\n        print(f\"Error training {name}: {e}\")\n\nprint(f\"\\n{'='*50}\")\nprint(\"Training completed!\")","metadata":{"id":"da972aed"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compare model performances\nprint(\"Model Performance Comparison:\")\nprint(\"=\" * 60)\n\n# Create comparison dataframe\ncomparison_data = []\nfor name, result in results.items():\n    comparison_data.append({\n        'Model': name,\n        'Accuracy': result['accuracy'],\n        'F1 Score': result['f1_score']\n    })\n\ncomparison_df = pd.DataFrame(comparison_data)\ncomparison_df = comparison_df.sort_values('Accuracy', ascending=False)\nprint(comparison_df.to_string(index=False))\n\n# Find the best model\nbest_model_name = comparison_df.iloc[0]['Model']\nbest_model = results[best_model_name]['model']\nprint(f\"\\nBest performing model: {best_model_name}\")\nprint(f\"Best accuracy: {comparison_df.iloc[0]['Accuracy']:.4f}\")\n\n# Visualize results\nplt.figure(figsize=(12, 5))\n\n# Plot 1: Accuracy comparison\nplt.subplot(1, 2, 1)\nplt.bar(range(len(comparison_df)), comparison_df['Accuracy'], color='skyblue')\nplt.xlabel('Models')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy Comparison')\nplt.xticks(range(len(comparison_df)),\n           comparison_df['Model'], rotation=45, ha='right')\nplt.ylim(0, 1)\n\n# Plot 2: F1 Score comparison\nplt.subplot(1, 2, 2)\nplt.bar(range(len(comparison_df)),\n        comparison_df['F1 Score'], color='lightcoral')\nplt.xlabel('Models')\nplt.ylabel('F1 Score')\nplt.title('Model F1 Score Comparison')\nplt.xticks(range(len(comparison_df)),\n           comparison_df['Model'], rotation=45, ha='right')\nplt.ylim(0, 1)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"41409abf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create confusion matrix for the best model\nbest_predictions = results[best_model_name]['predictions']\n\nplt.figure(figsize=(8, 6))\ncm = confusion_matrix(y_test, best_predictions)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Legitimate', 'Phishing'],\n            yticklabels=['Legitimate', 'Phishing'])\nplt.title(f'Confusion Matrix - {best_model_name}')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","metadata":{"id":"b28f0211"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to predict if a webpage is phishing or legitimate\ndef predict_webpage_status(webpage_code, model=None):\n    \"\"\"\n    Predict if a webpage is phishing (1) or legitimate (0) based on its HTML code.\n\n    Parameters:\n    webpage_code (str): The HTML code of the webpage\n    model: The trained model to use for prediction (default: best model)\n\n    Returns:\n    dict: Prediction result with probability scores\n    \"\"\"\n    if model is None:\n        model = best_model\n\n    # Make prediction\n    prediction = model.predict([webpage_code])[0]\n\n    # Get prediction probabilities\n    probabilities = model.predict_proba([webpage_code])[0]\n\n    # Create result dictionary\n    result = {\n        'prediction': prediction,\n        'status': 'Phishing' if prediction == 1 else 'Legitimate',\n        'confidence': max(probabilities),\n        'probability_legitimate': probabilities[0],\n        'probability_phishing': probabilities[1]\n    }\n\n    return result\n\n\n# Test the function with a sample from the test set\nsample_index = 22\nsample_code = X_test.iloc[sample_index]\nactual_label = y_test.iloc[sample_index]\n\nprediction_result = predict_webpage_status(sample_code)\n\nprint(\"Testing the prediction function:\")\nprint(\"=\" * 40)\nprint(\n    f\"Actual label: {actual_label} ({'Phishing' if actual_label == 1 else 'Legitimate'})\")\nprint(f\"Predicted: {prediction_result['status']}\")\nprint(f\"Confidence: {prediction_result['confidence']:.4f}\")\nprint(\n    f\"Probability Legitimate: {prediction_result['probability_legitimate']:.4f}\")\nprint(f\"Probability Phishing: {prediction_result['probability_phishing']:.4f}\")\n\n# Test with a few more samples\nprint(f\"\\nTesting with 5 random samples:\")\nprint(\"=\" * 50)\nfor i in range(5):\n    sample_code = X_test.iloc[i]\n    actual_label = y_test.iloc[i]\n    prediction_result = predict_webpage_status(sample_code)\n\n    correct = \"✓\" if prediction_result['prediction'] == actual_label else \"✗\"\n    print(f\"Sample {i+1}: Actual: {actual_label}, Predicted: {prediction_result['prediction']}, \"\n          f\"Confidence: {prediction_result['confidence']:.3f} {correct}\")","metadata":{"id":"b376a506"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phishing URL Detection","metadata":{"id":"ffcf6ac5"}},{"cell_type":"code","source":"url_dataSet = pd.read_csv(\n    \"/content/drive/MyDrive/Colab/phishing/new_data_urls.csv\",\n    nrows=400000\n)\nurl_dataSet.head()","metadata":{"id":"6e53c62c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare features and target for URL dataset\nfrom sklearn.model_selection import train_test_split\nurl_X = url_dataSet['url']\n# fallback if column name differs\nurl_y = url_dataSet['status']\n\nprint(f\"URL dataset shape: {url_dataSet.shape}\")\nprint(f\"Class distribution:\\n{url_y.value_counts()}\")\n\n# Split into train/test sets\nurl_X_train, url_X_test, url_y_train, url_y_test = train_test_split(\n    url_X, url_y, test_size=0.2, random_state=42, stratify=url_y\n)\nprint(f\"Train size: {len(url_X_train)}, Test size: {len(url_X_test)}\")","metadata":{"id":"3691584b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n\n\nurl_results = {}\nprint(\"Training and evaluating URL models...\")\nfor name, pipeline in pipelines.items():\n    print(f\"\\nTraining {name}...\")\n    try:\n        pipeline.fit(url_X_train, url_y_train)\n        y_pred = pipeline.predict(url_X_test)\n        acc = accuracy_score(url_y_test, y_pred)\n        f1 = f1_score(url_y_test, y_pred)\n        url_results[name] = {'accuracy': acc, 'f1_score': f1,\n                             'predictions': y_pred, 'model': pipeline}\n        print(f\"Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n    except Exception as e:\n        print(f\"Error training {name}: {e}\")","metadata":{"id":"2c2d8259"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compare URL model performances\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncomparison_url = []\nfor name, result in url_results.items():\n    comparison_url.append({\n        'Model': name,\n        'Accuracy': result['accuracy'],\n        'F1 Score': result['f1_score']\n    })\n\ncomparison_url_df = pd.DataFrame(\n    comparison_url).sort_values('Accuracy', ascending=False)\nprint(comparison_url_df.to_string(index=False))\n\nbest_url_model_name = comparison_url_df.iloc[0]['Model']\nbest_url_model = url_results[best_url_model_name]['model']\nprint(f\"\\nBest URL model: {best_url_model_name}\")\nprint(f\"Accuracy: {comparison_url_df.iloc[0]['Accuracy']:.4f}\")\n\n# Visualize accuracy and F1 score\nplt.figure(figsize=(10, 4))\nplt.bar(comparison_url_df['Model'], comparison_url_df['Accuracy'],\n        color='skyblue', label='Accuracy')\nplt.bar(comparison_url_df['Model'], comparison_url_df['F1 Score'],\n        color='lightcoral', alpha=0.7, label='F1 Score')\nplt.xticks(rotation=45, ha='right')\nplt.ylabel('Score')\nplt.title('Phishing URL Model Performance')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Confusion matrix for best model\ny_pred_best = url_results[best_url_model_name]['predictions']\ncm = confusion_matrix(url_y_test, y_pred_best)\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\n            'Legitimate', 'Phishing'], yticklabels=['Legitimate', 'Phishing'])\nplt.title(f'Confusion Matrix - {best_url_model_name}')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","metadata":{"id":"88796943"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a function to predict URL status\ndef predict_url_status(url, model=None):\n    \"\"\"\n    Predict if a URL is phishing (1) or legitimate (0) based on its text.\n\n    Parameters:\n    url (str): The URL to predict\n    model: The trained model to use for prediction (default: best model)\n\n    Returns:\n    dict: Prediction result with probability scores\n    \"\"\"\n    if model is None:\n        model = best_url_model\n\n    # Make prediction\n    prediction = model.predict([url])[0]\n\n    # Get prediction probabilities\n    probabilities = model.predict_proba([url])[0]\n\n    # Create result dictionary\n    result = {\n        'prediction': prediction,\n        'status': 'Legitimate' if prediction == 1 else 'Phishing',\n        'confidence': max(probabilities),\n        'probability_legitimate': probabilities[0],\n        'probability_phishing': probabilities[1]\n    }\n\n    return result","metadata":{"id":"ece739ce"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"url_sample = [\"google.com\", \"facebook.com\", \"phishing-test.com\",\n              \"example.com\", \"malicious-site.com\", 'facebook-test.com']\n\nprint(\"\\nTesting URL prediction function:\")\nfor url in url_sample:\n    result = predict_url_status(url)\n    print(f\"URL: {url} | Prediction: {result['status']} | \"\n          f\"Confidence: {result['confidence']:.4f} | \"\n          f\"Prob Legitimate: {result['probability_legitimate']:.4f} | \"\n          f\"Prob Phishing: {result['probability_phishing']:.4f}\")","metadata":{"id":"bb9b771a"},"outputs":[],"execution_count":null}]}