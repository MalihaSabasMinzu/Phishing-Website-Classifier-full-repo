{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12693261,"sourceType":"datasetVersion","datasetId":8021783},{"sourceId":12742804,"sourceType":"datasetVersion","datasetId":8055177},{"sourceId":12751295,"sourceType":"datasetVersion","datasetId":8060741}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predict from web_code","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\nfrom sklearn.pipeline import Pipeline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2025-08-09T19:16:59.797231Z","iopub.execute_input":"2025-08-09T19:16:59.798053Z","iopub.status.idle":"2025-08-09T19:17:07.527363Z","shell.execute_reply.started":"2025-08-09T19:16:59.797963Z","shell.execute_reply":"2025-08-09T19:17:07.526477Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import psutil\nimport gc\n\n\ndef get_memory_usage():\n    \"\"\"Get current memory usage\"\"\"\n    process = psutil.Process()\n    memory_info = process.memory_info()\n    memory_mb = memory_info.rss / 1024 / 1024\n    return memory_mb\n\n\ndef print_memory_usage(label=\"\"):\n    \"\"\"Print current memory usage with optional label\"\"\"\n    memory_mb = get_memory_usage()\n    print(f\"Memory usage {label}: {memory_mb:.2f} MB\")\n\n\ndef cleanup_memory():\n    \"\"\"Force garbage collection to free memory\"\"\"\n    gc.collect()\n    print(\"Memory cleanup completed\")\n\n\n# Print initial memory usage\nprint_memory_usage(\"(initial)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:17:07.528737Z","iopub.execute_input":"2025-08-09T19:17:07.529501Z","iopub.status.idle":"2025-08-09T19:17:07.537181Z","shell.execute_reply.started":"2025-08-09T19:17:07.529470Z","shell.execute_reply":"2025-08-09T19:17:07.536148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport joblib\nimport numpy as np\nfrom scipy.sparse import save_npz, load_npz, vstack\nimport gc\n\n# Check if we're running locally or on Kaggle\nif os.path.exists(\"/home/iqbal/Programming/ML/project/dataset/phishing_complete_dataset.csv\"):\n    dataset_path = \"/home/iqbal/Programming/ML/project/dataset/phishing_complete_dataset.csv\"\n    ARTIFACT_DIR = \"/home/iqbal/Programming/ML/project/artifacts/\"\nelse:\n    dataset_path = \"/kaggle/input/phishing-website-webcode-dataset/phishing_complete_dataset.csv\"\n    ARTIFACT_DIR = \"/kaggle/working/\"\n\n# Create artifacts directory if it doesn't exist\nos.makedirs(ARTIFACT_DIR, exist_ok=True)\n\n# First, let's check the total number of rows in the dataset\ntotal_rows = sum(1 for line in open(dataset_path)) - 1  # subtract 1 for header\nprint(f\"Total rows in dataset: {total_rows}\")\n\n# Read a small sample first to understand the data structure\nsample_df = pd.read_csv(dataset_path, nrows=5)\nprint(f\"Dataset columns: {sample_df.columns.tolist()}\")\nprint(f\"Sample data:\")\nprint(sample_df.head())","metadata":{"execution":{"iopub.status.busy":"2025-08-09T19:17:07.538017Z","iopub.execute_input":"2025-08-09T19:17:07.538445Z","iopub.status.idle":"2025-08-09T19:19:15.067138Z","shell.execute_reply.started":"2025-08-09T19:17:07.538411Z","shell.execute_reply":"2025-08-09T19:19:15.066019Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Batch processing configuration\nBATCH_SIZE = 2000\nCHUNK_SIZE = 2000\n\n\ndef process_dataset_in_batches():\n    \"\"\"Process dataset in batches to manage memory efficiently\"\"\"\n\n    # Initialize variables to track dataset statistics\n    total_processed = 0\n    class_counts = {}\n    code_lengths = []\n\n    print(\"Processing dataset in batches to analyze structure...\")\n\n    # Process dataset in chunks for analysis\n    chunk_iter = pd.read_csv(dataset_path, chunksize=CHUNK_SIZE)\n\n    for i, chunk in enumerate(chunk_iter):\n        print(\n            f\"Processing chunk {i+1}, rows {total_processed+1} to {total_processed+len(chunk)}\")\n\n        # Update class distribution\n        chunk_classes = chunk['result'].value_counts()\n        for class_label, count in chunk_classes.items():\n            class_counts[class_label] = class_counts.get(\n                class_label, 0) + count\n\n        # Sample some code lengths (to avoid memory issues)\n        if len(code_lengths) < 10000:  # Only sample first 10k for statistics\n            chunk_lengths = chunk['webpage_code'].str.len()\n            code_lengths.extend(chunk_lengths.tolist())\n\n        total_processed += len(chunk)\n\n        # Clear chunk from memory\n        del chunk\n        gc.collect()\n\n        if total_processed >= 10000:  # Limit analysis to first 10k rows for speed\n            break\n\n    print(f\"\\nDataset Analysis (first {total_processed} rows):\")\n    print(f\"Total processed: {total_processed}\")\n    print(f\"Class distribution: {class_counts}\")\n\n    if class_counts:\n        total_samples = sum(class_counts.values())\n        for class_label, count in class_counts.items():\n            percentage = (count / total_samples) * 100\n            print(f\"Class {class_label}: {count} ({percentage:.2f}%)\")\n\n    if code_lengths:\n        code_lengths_array = np.array(code_lengths)\n        print(f\"\\nWebpage code length statistics:\")\n        print(f\"Mean: {code_lengths_array.mean():.2f}\")\n        print(f\"Std: {code_lengths_array.std():.2f}\")\n        print(f\"Min: {code_lengths_array.min()}\")\n        print(f\"Max: {code_lengths_array.max()}\")\n        print(f\"Median: {np.median(code_lengths_array):.2f}\")\n\n\n# Run the analysis\nprocess_dataset_in_batches()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:19:15.070318Z","iopub.execute_input":"2025-08-09T19:19:15.070626Z","iopub.status.idle":"2025-08-09T19:19:43.686398Z","shell.execute_reply.started":"2025-08-09T19:19:15.070598Z","shell.execute_reply":"2025-08-09T19:19:43.685542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_train_test_split_batched():\n    \"\"\"Create train-test split while processing dataset in batches\"\"\"\n\n    print(\"Creating train-test split with batched processing...\")\n\n    # First pass: collect all data for proper stratified split\n    all_X = []\n    all_y = []\n\n    chunk_iter = pd.read_csv(dataset_path, chunksize=CHUNK_SIZE)\n\n    for i, chunk in enumerate(chunk_iter):\n        print(f\"Reading chunk {i+1} for train-test split...\")\n        all_X.extend(chunk['webpage_code'].tolist())\n        all_y.extend(chunk['result'].tolist())\n        del chunk\n        gc.collect()\n\n    print(f\"Total samples loaded: {len(all_X)}\")\n\n    # Convert to pandas Series for train_test_split\n    X_series = pd.Series(all_X)\n    y_series = pd.Series(all_y)\n\n    # Create stratified train-test split\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_series, y_series, test_size=0.2, random_state=42, stratify=y_series\n    )\n\n    print(f\"Training set size: {len(X_train)}\")\n    print(f\"Test set size: {len(X_test)}\")\n    print(f\"Training target distribution:\\n{y_train.value_counts()}\")\n    print(f\"Test target distribution:\\n{y_test.value_counts()}\")\n\n    # Clear original data from memory\n    del all_X, all_y, X_series, y_series\n    gc.collect()\n\n    return X_train, X_test, y_train, y_test\n\n\n# Create the train-test split\nX_train, X_test, y_train, y_test = create_train_test_split_batched()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:19:43.687205Z","iopub.execute_input":"2025-08-09T19:19:43.687449Z","iopub.status.idle":"2025-08-09T19:22:02.434639Z","shell.execute_reply.started":"2025-08-09T19:19:43.687427Z","shell.execute_reply":"2025-08-09T19:22:02.433735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def vectorize_data_in_batches(X_train, X_test, y_train, y_test):\n    \"\"\"Vectorize training and test data in batches to manage memory\"\"\"\n\n    print(\"Starting batch vectorization...\")\n\n    # Initialize TF-IDF vectorizer\n    tfidf_vectorizer = TfidfVectorizer(\n        max_features=5000,\n        stop_words='english',\n        ngram_range=(1, 2)\n    )\n\n    # Convert to lists for batch processing\n    X_train_list = X_train.tolist()\n    X_test_list = X_test.tolist()\n\n    # Fit vectorizer on training data in batches\n    print(\"Fitting TF-IDF vectorizer on training data...\")\n\n    # For fitting, we need to process all training data\n    # We'll do this in batches but accumulate the vocabulary\n    train_batches = [X_train_list[i:i+BATCH_SIZE]\n                     for i in range(0, len(X_train_list), BATCH_SIZE)]\n\n    print(f\"Processing {len(train_batches)} training batches...\")\n\n    # Fit on the first few batches to establish vocabulary\n    # Use up to 10k samples for fitting\n    sample_size = min(10000, len(X_train_list))\n    sample_data = X_train_list[:sample_size]\n    tfidf_vectorizer.fit(sample_data)\n\n    print(\"Vectorizer fitted. Now transforming training data in batches...\")\n\n    # Transform training data in batches and save\n    X_train_tfidf_batches = []\n    for i, batch in enumerate(train_batches):\n        print(f\"Transforming training batch {i+1}/{len(train_batches)}\")\n        batch_tfidf = tfidf_vectorizer.transform(batch)\n        X_train_tfidf_batches.append(batch_tfidf)\n\n        # Save batch to disk to free memory\n        batch_filename = os.path.join(\n            ARTIFACT_DIR, f\"X_train_tfidf_batch_{i}.npz\")\n        save_npz(batch_filename, batch_tfidf)\n\n        # Clear batch from memory\n        del batch_tfidf\n        gc.collect()\n\n    print(\"Training data vectorization completed. Now processing test data...\")\n\n    # Transform test data in batches\n    test_batches = [X_test_list[i:i+BATCH_SIZE]\n                    for i in range(0, len(X_test_list), BATCH_SIZE)]\n    X_test_tfidf_batches = []\n\n    for i, batch in enumerate(test_batches):\n        print(f\"Transforming test batch {i+1}/{len(test_batches)}\")\n        batch_tfidf = tfidf_vectorizer.transform(batch)\n        X_test_tfidf_batches.append(batch_tfidf)\n\n        # Save batch to disk\n        batch_filename = os.path.join(\n            ARTIFACT_DIR, f\"X_test_tfidf_batch_{i}.npz\")\n        save_npz(batch_filename, batch_tfidf)\n\n        # Clear batch from memory\n        del batch_tfidf\n        gc.collect()\n\n    print(\"Combining all training batches...\")\n    # Load and combine all training batches\n    X_train_tfidf = None\n    for i in range(len(train_batches)):\n        batch_filename = os.path.join(\n            ARTIFACT_DIR, f\"X_train_tfidf_batch_{i}.npz\")\n        batch_data = load_npz(batch_filename)\n\n        if X_train_tfidf is None:\n            X_train_tfidf = batch_data\n        else:\n            X_train_tfidf = vstack([X_train_tfidf, batch_data])\n\n        # Clean up temporary file\n        os.remove(batch_filename)\n\n    print(\"Combining all test batches...\")\n    # Load and combine all test batches\n    X_test_tfidf = None\n    for i in range(len(test_batches)):\n        batch_filename = os.path.join(\n            ARTIFACT_DIR, f\"X_test_tfidf_batch_{i}.npz\")\n        batch_data = load_npz(batch_filename)\n\n        if X_test_tfidf is None:\n            X_test_tfidf = batch_data\n        else:\n            X_test_tfidf = vstack([X_test_tfidf, batch_data])\n\n        # Clean up temporary file\n        os.remove(batch_filename)\n\n    print(f\"Vectorization completed!\")\n    print(f\"Training data shape: {X_train_tfidf.shape}\")\n    print(f\"Test data shape: {X_test_tfidf.shape}\")\n\n    # Clear original text data from memory\n    del X_train_list, X_test_list\n    gc.collect()\n\n    return tfidf_vectorizer, X_train_tfidf, X_test_tfidf\n\n\n# Perform batch vectorization\ntfidf_vectorizer, X_train_tfidf, X_test_tfidf = vectorize_data_in_batches(\n    X_train, X_test, y_train, y_test)\n\n# Clear original text data\ndel X_train, X_test\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:22:02.435862Z","iopub.execute_input":"2025-08-09T19:22:02.436145Z","iopub.status.idle":"2025-08-09T19:56:18.085753Z","shell.execute_reply.started":"2025-08-09T19:22:02.436122Z","shell.execute_reply":"2025-08-09T19:56:18.084839Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_processed_data():\n    \"\"\"Save all processed data and vectorizer to disk\"\"\"\n\n    print(\"Saving processed data to disk...\")\n\n    # Save vectorizer\n    vectorizer_path = os.path.join(ARTIFACT_DIR, \"tfidf_vectorizer.joblib\")\n    joblib.dump(tfidf_vectorizer, vectorizer_path)\n    print(f\"‚úì Saved TF-IDF vectorizer to {vectorizer_path}\")\n\n    # Save vectorized training data\n    train_tfidf_path = os.path.join(ARTIFACT_DIR, \"X_train_tfidf.npz\")\n    save_npz(train_tfidf_path, X_train_tfidf)\n    print(f\"‚úì Saved training TF-IDF data to {train_tfidf_path}\")\n\n    # Save vectorized test data\n    test_tfidf_path = os.path.join(ARTIFACT_DIR, \"X_test_tfidf.npz\")\n    save_npz(test_tfidf_path, X_test_tfidf)\n    print(f\"‚úì Saved test TF-IDF data to {test_tfidf_path}\")\n\n    # Save target variables\n    y_train_np = y_train.to_numpy() if hasattr(\n        y_train, \"to_numpy\") else np.asarray(y_train)\n    y_test_np = y_test.to_numpy() if hasattr(\n        y_test, \"to_numpy\") else np.asarray(y_test)\n\n    y_train_path = os.path.join(ARTIFACT_DIR, \"y_train.npy\")\n    y_test_path = os.path.join(ARTIFACT_DIR, \"y_test.npy\")\n\n    np.save(y_train_path, y_train_np)\n    np.save(y_test_path, y_test_np)\n    print(f\"‚úì Saved training targets to {y_train_path}\")\n    print(f\"‚úì Saved test targets to {y_test_path}\")\n\n    # Print file sizes for verification\n    print(\"\\nFile sizes:\")\n    for filename in [\"tfidf_vectorizer.joblib\", \"X_train_tfidf.npz\", \"X_test_tfidf.npz\", \"y_train.npy\", \"y_test.npy\"]:\n        filepath = os.path.join(ARTIFACT_DIR, filename)\n        if os.path.exists(filepath):\n            size_mb = os.path.getsize(filepath) / (1024 * 1024)\n            print(f\"  {filename}: {size_mb:.2f} MB\")\n\n    print(f\"\\n‚úÖ All data saved successfully to '{ARTIFACT_DIR}'\")\n\n    return {\n        'vectorizer_path': vectorizer_path,\n        'train_tfidf_path': train_tfidf_path,\n        'test_tfidf_path': test_tfidf_path,\n        'y_train_path': y_train_path,\n        'y_test_path': y_test_path\n    }\n\n\n# Save all processed data\nsaved_paths = save_processed_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:56:18.088137Z","iopub.execute_input":"2025-08-09T19:56:18.088401Z","iopub.status.idle":"2025-08-09T19:58:10.296037Z","shell.execute_reply.started":"2025-08-09T19:56:18.088378Z","shell.execute_reply":"2025-08-09T19:58:10.294842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_processed_data():\n    \"\"\"Load previously saved processed data for model training\"\"\"\n\n    print(\"Loading processed data from disk...\")\n\n    # Check if all required files exist\n    required_files = [\n        \"tfidf_vectorizer.joblib\",\n        \"X_train_tfidf.npz\",\n        \"X_test_tfidf.npz\",\n        \"y_train.npy\",\n        \"y_test.npy\"\n    ]\n\n    missing_files = []\n    for filename in required_files:\n        filepath = os.path.join(ARTIFACT_DIR, filename)\n        if not os.path.exists(filepath):\n            missing_files.append(filename)\n\n    if missing_files:\n        print(f\"‚ùå Missing files: {missing_files}\")\n        print(\"Please run the data processing cells first.\")\n        return None\n\n    # Load vectorizer\n    vectorizer_path = os.path.join(ARTIFACT_DIR, \"tfidf_vectorizer.joblib\")\n    loaded_vectorizer = joblib.load(vectorizer_path)\n    print(f\"‚úì Loaded TF-IDF vectorizer from {vectorizer_path}\")\n\n    # Load vectorized data\n    train_tfidf_path = os.path.join(ARTIFACT_DIR, \"X_train_tfidf.npz\")\n    test_tfidf_path = os.path.join(ARTIFACT_DIR, \"X_test_tfidf.npz\")\n\n    loaded_X_train_tfidf = load_npz(train_tfidf_path)\n    loaded_X_test_tfidf = load_npz(test_tfidf_path)\n    print(f\"‚úì Loaded training TF-IDF data: {loaded_X_train_tfidf.shape}\")\n    print(f\"‚úì Loaded test TF-IDF data: {loaded_X_test_tfidf.shape}\")\n\n    # Load target variables\n    y_train_path = os.path.join(ARTIFACT_DIR, \"y_train.npy\")\n    y_test_path = os.path.join(ARTIFACT_DIR, \"y_test.npy\")\n\n    loaded_y_train = np.load(y_train_path)\n    loaded_y_test = np.load(y_test_path)\n    print(f\"‚úì Loaded training targets: {loaded_y_train.shape}\")\n    print(f\"‚úì Loaded test targets: {loaded_y_test.shape}\")\n\n    print(f\"\\n‚úÖ All data loaded successfully!\")\n\n    return {\n        'vectorizer': loaded_vectorizer,\n        'X_train_tfidf': loaded_X_train_tfidf,\n        'X_test_tfidf': loaded_X_test_tfidf,\n        'y_train': loaded_y_train,\n        'y_test': loaded_y_test\n    }\n\n# Uncomment the next line if you want to load previously saved data instead of processing\n# loaded_data = load_processed_data()\n# if loaded_data:\n#     tfidf_vectorizer = loaded_data['vectorizer']\n#     X_train_tfidf = loaded_data['X_train_tfidf']\n#     X_test_tfidf = loaded_data['X_test_tfidf']\n#     y_train = loaded_data['y_train']\n#     y_test = loaded_data['y_test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:58:10.297522Z","iopub.execute_input":"2025-08-09T19:58:10.297879Z","iopub.status.idle":"2025-08-09T19:58:10.309317Z","shell.execute_reply.started":"2025-08-09T19:58:10.297847Z","shell.execute_reply":"2025-08-09T19:58:10.308023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_models_on_processed_data():\n    \"\"\"Train models using the processed and vectorized data\"\"\"\n\n    results = {}\n\n    # Define classifiers for TF-IDF data\n    classifiers_tfidf = {\n        'Random Forest (TF-IDF)': RandomForestClassifier(n_estimators=100, random_state=42),\n        'XGBoost (TF-IDF)': xgb.XGBClassifier(random_state=42, verbosity=0),\n        'LightGBM (TF-IDF)': lgb.LGBMClassifier(random_state=42, verbose=-1),\n        'Extra Trees (TF-IDF)': ExtraTreesClassifier(n_estimators=100, random_state=42),\n        'Naive Bayes (TF-IDF)': MultinomialNB(),\n        'Logistic Regression (TF-IDF)': LogisticRegression(random_state=42, max_iter=1000)\n    }\n\n    print(\"Training and evaluating models on processed data...\")\n    print(\"=\" * 60)\n    print(f\"Training data shape: {X_train_tfidf.shape}\")\n    print(f\"Test data shape: {X_test_tfidf.shape}\")\n    print(\"=\" * 60)\n\n    # Train TF-IDF models\n    for name, clf in classifiers_tfidf.items():\n        print(f\"\\nüöÄ Training {name}...\")\n        try:\n            # Train the model\n            clf.fit(X_train_tfidf, y_train)\n\n            # Make predictions\n            y_pred = clf.predict(X_test_tfidf)\n\n            # Calculate metrics\n            accuracy = accuracy_score(y_test, y_pred)\n            f1 = f1_score(y_test, y_pred)\n\n            # Store results\n            results[name] = {\n                'accuracy': accuracy,\n                'f1_score': f1,\n                'predictions': y_pred,\n                'model': clf\n            }\n\n            print(f\"   ‚úÖ Accuracy: {accuracy:.4f}\")\n            print(f\"   ‚úÖ F1 Score: {f1:.4f}\")\n\n            # Save the trained model\n            model_filename = f\"{name.replace(' ', '_').replace('(', '').replace(')', '').lower()}.joblib\"\n            model_path = os.path.join(ARTIFACT_DIR, model_filename)\n            joblib.dump(clf, model_path)\n            print(f\"   üíæ Saved model to {model_filename}\")\n\n        except Exception as e:\n            print(f\"   ‚ùå Error training {name}: {e}\")\n\n    print(f\"\\n{'='*60}\")\n    print(\"üéâ Training completed!\")\n\n    return results\n\n\n# Train all models\nresults = train_models_on_processed_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:58:10.310383Z","iopub.execute_input":"2025-08-09T19:58:10.310662Z","iopub.status.idle":"2025-08-09T20:23:22.170167Z","shell.execute_reply.started":"2025-08-09T19:58:10.310632Z","shell.execute_reply":"2025-08-09T20:23:22.168928Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compare model performances\nprint(\"Model Performance Comparison:\")\nprint(\"=\" * 60)\n\n# Create comparison dataframe\ncomparison_data = []\nfor name, result in results.items():\n    comparison_data.append({\n        'Model': name,\n        'Accuracy': result['accuracy'],\n        'F1 Score': result['f1_score']\n    })\n\ncomparison_df = pd.DataFrame(comparison_data)\ncomparison_df = comparison_df.sort_values('Accuracy', ascending=False)\nprint(comparison_df.to_string(index=False))\n\n# Find the best model\nbest_model_name = comparison_df.iloc[0]['Model']\nbest_model = results[best_model_name]['model']\nprint(f\"\\nBest performing model: {best_model_name}\")\nprint(f\"Best accuracy: {comparison_df.iloc[0]['Accuracy']:.4f}\")\n\n# Visualize results\nplt.figure(figsize=(12, 5))\n\n# Plot 1: Accuracy comparison\nplt.subplot(1, 2, 1)\nplt.bar(range(len(comparison_df)), comparison_df['Accuracy'], color='skyblue')\nplt.xlabel('Models')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy Comparison')\nplt.xticks(range(len(comparison_df)),\n           comparison_df['Model'], rotation=45, ha='right')\nplt.ylim(0, 1)\n\n# Plot 2: F1 Score comparison\nplt.subplot(1, 2, 2)\nplt.bar(range(len(comparison_df)),\n        comparison_df['F1 Score'], color='lightcoral')\nplt.xlabel('Models')\nplt.ylabel('F1 Score')\nplt.title('Model F1 Score Comparison')\nplt.xticks(range(len(comparison_df)),\n           comparison_df['Model'], rotation=45, ha='right')\nplt.ylim(0, 1)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:23:22.174336Z","iopub.execute_input":"2025-08-09T20:23:22.174655Z","iopub.status.idle":"2025-08-09T20:23:22.697670Z","shell.execute_reply.started":"2025-08-09T20:23:22.174632Z","shell.execute_reply":"2025-08-09T20:23:22.696833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create confusion matrix for the best model\nbest_predictions = results[best_model_name]['predictions']\n\nplt.figure(figsize=(8, 6))\ncm = confusion_matrix(y_test, best_predictions)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Legitimate', 'Phishing'],\n            yticklabels=['Legitimate', 'Phishing'])\nplt.title(f'Confusion Matrix - {best_model_name}')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:23:22.698571Z","iopub.execute_input":"2025-08-09T20:23:22.698908Z","iopub.status.idle":"2025-08-09T20:23:22.894818Z","shell.execute_reply.started":"2025-08-09T20:23:22.698879Z","shell.execute_reply":"2025-08-09T20:23:22.894105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to predict if a webpage is phishing or legitimate\ndef predict_webpage_status(webpage_code, model=None, vectorizer=None):\n    \"\"\"\n    Predict if a webpage is phishing (1) or legitimate (0) based on its HTML code.\n\n    Parameters:\n    webpage_code (str): The HTML code of the webpage\n    model: The trained model to use for prediction (default: best model)\n    vectorizer: The TF-IDF vectorizer to use (default: loaded vectorizer)\n\n    Returns:\n    dict: Prediction result with probability scores\n    \"\"\"\n    if model is None:\n        if 'best_model' in globals():\n            model = best_model\n        else:\n            print(\"‚ùå No model available. Please train models first.\")\n            return None\n\n    if vectorizer is None:\n        if 'tfidf_vectorizer' in globals():\n            vectorizer = tfidf_vectorizer\n        else:\n            print(\"‚ùå No vectorizer available. Please load processed data first.\")\n            return None\n\n    try:\n        # Vectorize the input\n        webpage_vectorized = vectorizer.transform([webpage_code])\n\n        # Make prediction\n        prediction = model.predict(webpage_vectorized)[0]\n\n        # Get prediction probabilities\n        probabilities = model.predict_proba(webpage_vectorized)[0]\n\n        # Create result dictionary\n        result = {\n            'prediction': prediction,\n            'status': 'Phishing' if prediction == 1 else 'Legitimate',\n            'confidence': max(probabilities),\n            'probability_legitimate': probabilities[0],\n            'probability_phishing': probabilities[1]\n        }\n\n        return result\n\n    except Exception as e:\n        print(f\"‚ùå Error making prediction: {e}\")\n        return None\n\n\ndef load_model_for_prediction(model_name):\n    \"\"\"Load a specific trained model for prediction\"\"\"\n    model_filename = f\"{model_name.replace(' ', '_').replace('(', '').replace(')', '').lower()}.joblib\"\n    model_path = os.path.join(ARTIFACT_DIR, model_filename)\n\n    if os.path.exists(model_path):\n        loaded_model = joblib.load(model_path)\n        print(f\"‚úÖ Loaded model: {model_name}\")\n        return loaded_model\n    else:\n        print(f\"‚ùå Model file not found: {model_path}\")\n        return None\n\n# Test the prediction function once models are trained\n\n\ndef test_prediction_function():\n    \"\"\"Test the prediction function with sample data\"\"\"\n\n    if 'results' not in globals() or not results:\n        print(\"‚ùå No trained models available. Please train models first.\")\n        return\n\n    # Get the best model\n    comparison_data = []\n    for name, result in results.items():\n        comparison_data.append({\n            'Model': name,\n            'Accuracy': result['accuracy'],\n            'F1 Score': result['f1_score']\n        })\n\n    comparison_df = pd.DataFrame(comparison_data).sort_values(\n        'Accuracy', ascending=False)\n    best_model_name = comparison_df.iloc[0]['Model']\n    best_model = results[best_model_name]['model']\n\n    print(f\"Using best model: {best_model_name}\")\n    print(f\"Best accuracy: {comparison_df.iloc[0]['Accuracy']:.4f}\")\n\n    # Test with sample HTML codes\n    test_samples = [\n        \"<html><head><title>Google</title></head><body>Welcome to Google</body></html>\",\n        \"<html><head><title>Secure Bank Login</title></head><body><form>Enter password</form></body></html>\",\n        \"<html><script>window.location='phishing-site.com'</script></html>\",\n        \"<html><body>Click here to verify your account: <a href='fake-bank.com'>Verify</a></body></html>\"\n    ]\n\n    print(\"\\nüß™ Testing prediction function with sample HTML codes:\")\n    print(\"=\" * 60)\n\n    for i, sample in enumerate(test_samples, 1):\n        result = predict_webpage_status(sample, best_model, tfidf_vectorizer)\n        if result:\n            print(\n                f\"Sample {i}: {result['status']} (confidence: {result['confidence']:.3f})\")\n            print(f\"  HTML: {sample[:50]}...\")\n            print(f\"  Prob Legitimate: {result['probability_legitimate']:.3f}\")\n            print(f\"  Prob Phishing: {result['probability_phishing']:.3f}\")\n            print()\n\n# Note: Run test_prediction_function() after training models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:23:22.896314Z","iopub.execute_input":"2025-08-09T20:23:22.896933Z","iopub.status.idle":"2025-08-09T20:23:22.910395Z","shell.execute_reply.started":"2025-08-09T20:23:22.896905Z","shell.execute_reply":"2025-08-09T20:23:22.909452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üéØ Batch Processing Workflow Summary\nprint(\"\"\"\nüìä BATCH PROCESSING WORKFLOW FOR PHISHING DETECTION\n==================================================\n\nThis notebook implements an efficient batch processing approach for handling large datasets:\n\nüîÑ WORKFLOW STEPS:\n1. ‚úÖ Load dataset in chunks (2000 rows at a time)\n2. ‚úÖ Analyze dataset structure and statistics \n3. ‚úÖ Create stratified train-test split\n4. ‚úÖ Vectorize data in batches using TF-IDF\n5. ‚úÖ Save vectorized data and vectorizer to disk\n6. ‚úÖ Train multiple models on processed data\n7. ‚úÖ Save trained models for future use\n8. ‚úÖ Evaluate and compare model performance\n\nüíæ SAVED ARTIFACTS:\n- tfidf_vectorizer.joblib      (TF-IDF vectorizer)\n- X_train_tfidf.npz           (Training features)\n- X_test_tfidf.npz            (Test features) \n- y_train.npy                 (Training labels)\n- y_test.npy                  (Test labels)\n- [model_name].joblib         (Trained models)\n\nüöÄ MEMORY MANAGEMENT:\n- Processes data in 2000-row batches\n- Saves intermediate results to disk\n- Cleans up memory after each batch\n- Monitors memory usage throughout\n\nüìà MODELS TRAINED:\n- Random Forest\n- XGBoost  \n- LightGBM\n- Extra Trees\n- Naive Bayes\n- Logistic Regression\n\nüéØ USAGE:\n1. Run all cells in sequence to process data and train models\n2. Use load_processed_data() to reload saved data\n3. Use predict_webpage_status() for new predictions\n4. Use test_prediction_function() to test the prediction pipeline\n\nüí° BENEFITS:\n- Handles datasets larger than available RAM\n- Reproducible results with saved artifacts  \n- Memory efficient processing\n- Easy to resume from saved state\n\"\"\")\n\n# Print current status\nprint(f\"\\nüìç CURRENT STATUS:\")\nprint(f\"Working directory: {os.getcwd()}\")\nprint(f\"Artifact directory: {ARTIFACT_DIR}\")\nprint(f\"Dataset path: {dataset_path}\")\n\n# Check if processed data exists\nif os.path.exists(os.path.join(ARTIFACT_DIR, \"tfidf_vectorizer.joblib\")):\n    print(\"‚úÖ Processed data available\")\nelse:\n    print(\"‚è≥ Processed data not yet created - run processing cells first\")\n\n# Memory status\nprint_memory_usage(\"(current)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:23:22.911659Z","iopub.execute_input":"2025-08-09T20:23:22.912000Z","iopub.status.idle":"2025-08-09T20:23:22.935092Z","shell.execute_reply.started":"2025-08-09T20:23:22.911972Z","shell.execute_reply":"2025-08-09T20:23:22.934127Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phishing URL Detection","metadata":{}},{"cell_type":"code","source":"url_dataSet = pd.read_csv(\n    \"/kaggle/input/phising-website-url-dataset/new_data_urls.csv\"\n)\nurl_dataSet.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:23:22.935913Z","iopub.execute_input":"2025-08-09T20:23:22.936162Z","iopub.status.idle":"2025-08-09T20:23:24.790077Z","shell.execute_reply.started":"2025-08-09T20:23:22.936142Z","shell.execute_reply":"2025-08-09T20:23:24.789216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\ndef move_files_to_tfidf_directory():\n    \"\"\"\n    Move all files from /kaggle/working/ to /kaggle/working/tfidf/\n    \"\"\"\n    \n    source_dir = \"/kaggle/working/\"\n    target_dir = \"/kaggle/working/tfidf/\"\n    \n    print(\"üîÑ Moving files to TF-IDF directory...\")\n    \n    # Create target directory if it doesn't exist\n    os.makedirs(target_dir, exist_ok=True)\n    print(f\"‚úì Created directory: {target_dir}\")\n    \n    # Get list of all files in source directory (excluding subdirectories)\n    try:\n        files_in_source = [f for f in os.listdir(source_dir) \n                          if os.path.isfile(os.path.join(source_dir, f))]\n        \n        if not files_in_source:\n            print(\"‚ÑπÔ∏è No files found in source directory to move.\")\n            return\n        \n        print(f\"üìÅ Found {len(files_in_source)} files to move:\")\n        \n        moved_count = 0\n        for filename in files_in_source:\n            source_path = os.path.join(source_dir, filename)\n            target_path = os.path.join(target_dir, filename)\n            \n            try:\n                # Move the file (cut and paste)\n                shutil.move(source_path, target_path)\n                print(f\"  ‚úì Moved: {filename}\")\n                moved_count += 1\n                \n            except Exception as e:\n                print(f\"  ‚ùå Error moving {filename}: {e}\")\n        \n        print(f\"\\nüéâ Successfully moved {moved_count}/{len(files_in_source)} files!\")\n        \n        # Verify the move\n        files_in_target = [f for f in os.listdir(target_dir) \n                          if os.path.isfile(os.path.join(target_dir, f))]\n        print(f\"üìÇ Files now in {target_dir}: {len(files_in_target)}\")\n        \n        # List files in target directory\n        if files_in_target:\n            print(\"üìã Files in TF-IDF directory:\")\n            for i, filename in enumerate(files_in_target, 1):\n                filepath = os.path.join(target_dir, filename)\n                size_mb = os.path.getsize(filepath) / (1024 * 1024)\n                print(f\"  {i}. {filename} ({size_mb:.2f} MB)\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error accessing source directory: {e}\")\n\n\n\n# Complete workflow function\ndef organize_files_for_tfidf():\n    \"\"\"\n    Complete workflow to organize files for TF-IDF processing\n    \"\"\"\n    print(\"üéØ ORGANIZING FILES FOR TF-IDF PROCESSING\")\n    print(\"=\" * 50)\n    \n    # Step 1: Move files\n    move_files_to_tfidf_directory()\n    \n\n    \n    # Step 3: Verify organization\n    print(\"\\nüîç Verifying file organization...\")\n    if os.path.exists(\"/kaggle/working/tfidf/\"):\n        files = os.listdir(\"/kaggle/working/tfidf/\")\n        print(f\"‚úì TF-IDF directory contains {len(files)} items\")\n        \n        # Check for required TF-IDF files\n        required_tfidf_files = [\n            \"tfidf_vectorizer.joblib\",\n            \"X_train_tfidf.npz\", \n            \"X_test_tfidf.npz\",\n            \"y_train.npy\",\n            \"y_test.npy\"\n        ]\n        \n        found_files = []\n        missing_files = []\n        \n        for filename in required_tfidf_files:\n            if filename in files:\n                found_files.append(filename)\n            else:\n                missing_files.append(filename)\n        \n        if found_files:\n            print(f\"‚úì Found TF-IDF files: {found_files}\")\n        if missing_files:\n            print(f\"‚ö†Ô∏è Missing TF-IDF files: {missing_files}\")\n    \n    print(\"\\n‚úÖ File organization complete!\")\n\n# Run the organization\norganize_files_for_tfidf()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:36:12.351070Z","iopub.execute_input":"2025-08-09T20:36:12.351970Z","iopub.status.idle":"2025-08-09T20:36:12.367346Z","shell.execute_reply.started":"2025-08-09T20:36:12.351940Z","shell.execute_reply":"2025-08-09T20:36:12.366527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare features and target for URL dataset\nfrom sklearn.model_selection import train_test_split\nurl_X = url_dataSet['url']\n# fallback if column name differs\nurl_y = url_dataSet['status']\n\nprint(f\"URL dataset shape: {url_dataSet.shape}\")\nprint(f\"Class distribution:\\n{url_y.value_counts()}\")\n\n# Split into train/test sets\nurl_X_train, url_X_test, url_y_train, url_y_test = train_test_split(\n    url_X, url_y, test_size=0.2, random_state=42, stratify=url_y\n)\nprint(f\"Train size: {len(url_X_train)}, Test size: {len(url_X_test)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:23:24.790979Z","iopub.execute_input":"2025-08-09T20:23:24.791229Z","iopub.status.idle":"2025-08-09T20:23:25.330610Z","shell.execute_reply.started":"2025-08-09T20:23:24.791209Z","shell.execute_reply":"2025-08-09T20:23:25.329713Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n\n\nurl_results = {}\nprint(\"Training and evaluating URL models...\")\nfor name, pipeline in pipelines.items():\n    print(f\"\\nTraining {name}...\")\n    try:\n        pipeline.fit(url_X_train, url_y_train)\n        y_pred = pipeline.predict(url_X_test)\n        acc = accuracy_score(url_y_test, y_pred)\n        f1 = f1_score(url_y_test, y_pred)\n        url_results[name] = {'accuracy': acc, 'f1_score': f1,\n                             'predictions': y_pred, 'model': pipeline}\n        print(f\"Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n    except Exception as e:\n        print(f\"Error training {name}: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:23:25.331655Z","iopub.execute_input":"2025-08-09T20:23:25.332069Z","iopub.status.idle":"2025-08-09T20:23:25.675950Z","shell.execute_reply.started":"2025-08-09T20:23:25.332042Z","shell.execute_reply":"2025-08-09T20:23:25.674832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compare URL model performances\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncomparison_url = []\nfor name, result in url_results.items():\n    comparison_url.append({\n        'Model': name,\n        'Accuracy': result['accuracy'],\n        'F1 Score': result['f1_score']\n    })\n\ncomparison_url_df = pd.DataFrame(\n    comparison_url).sort_values('Accuracy', ascending=False)\nprint(comparison_url_df.to_string(index=False))\n\nbest_url_model_name = comparison_url_df.iloc[0]['Model']\nbest_url_model = url_results[best_url_model_name]['model']\nprint(f\"\\nBest URL model: {best_url_model_name}\")\nprint(f\"Accuracy: {comparison_url_df.iloc[0]['Accuracy']:.4f}\")\n\n# Visualize accuracy and F1 score\nplt.figure(figsize=(10, 4))\nplt.bar(comparison_url_df['Model'], comparison_url_df['Accuracy'],\n        color='skyblue', label='Accuracy')\nplt.bar(comparison_url_df['Model'], comparison_url_df['F1 Score'],\n        color='lightcoral', alpha=0.7, label='F1 Score')\nplt.xticks(rotation=45, ha='right')\nplt.ylabel('Score')\nplt.title('Phishing URL Model Performance')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Confusion matrix for best model\ny_pred_best = url_results[best_url_model_name]['predictions']\ncm = confusion_matrix(url_y_test, y_pred_best)\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\n            'Legitimate', 'Phishing'], yticklabels=['Legitimate', 'Phishing'])\nplt.title(f'Confusion Matrix - {best_url_model_name}')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:23:25.676639Z","iopub.status.idle":"2025-08-09T20:23:25.676944Z","shell.execute_reply.started":"2025-08-09T20:23:25.676796Z","shell.execute_reply":"2025-08-09T20:23:25.676812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a function to predict URL status\ndef predict_url_status(url, model=None):\n    \"\"\"\n    Predict if a URL is phishing (1) or legitimate (0) based on its text.\n\n    Parameters:\n    url (str): The URL to predict\n    model: The trained model to use for prediction (default: best model)\n\n    Returns:\n    dict: Prediction result with probability scores\n    \"\"\"\n    if model is None:\n        model = best_url_model\n\n    # Make prediction\n    prediction = model.predict([url])[0]\n\n    # Get prediction probabilities\n    probabilities = model.predict_proba([url])[0]\n\n    # Create result dictionary\n    result = {\n        'prediction': prediction,\n        'status': 'Legitimate' if prediction == 1 else 'Phishing',\n        'confidence': max(probabilities),\n        'probability_legitimate': probabilities[0],\n        'probability_phishing': probabilities[1]\n    }\n\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:23:25.678346Z","iopub.status.idle":"2025-08-09T20:23:25.678727Z","shell.execute_reply.started":"2025-08-09T20:23:25.678534Z","shell.execute_reply":"2025-08-09T20:23:25.678551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"url_sample = [\"google.com\", \"facebook.com\", \"phishing-test.com\",\n              \"example.com\", \"malicious-site.com\", 'facebook-test.com']\n\nprint(\"\\nTesting URL prediction function:\")\nfor url in url_sample:\n    result = predict_url_status(url)\n    print(f\"URL: {url} | Prediction: {result['status']} | \"\n          f\"Confidence: {result['confidence']:.4f} | \"\n          f\"Prob Legitimate: {result['probability_legitimate']:.4f} | \"\n          f\"Prob Phishing: {result['probability_phishing']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:23:25.680373Z","iopub.status.idle":"2025-08-09T20:23:25.680736Z","shell.execute_reply.started":"2025-08-09T20:23:25.680552Z","shell.execute_reply":"2025-08-09T20:23:25.680567Z"}},"outputs":[],"execution_count":null}]}